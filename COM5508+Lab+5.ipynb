{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'weakly positively \\ncorrelated')"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAGECAYAAAAiBAt3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ef3ed64358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes=plt.subplots(2,2,figsize=(6,6),sharey=True,sharex=True)\n",
    "\n",
    "x1=np.random.randn(100)\n",
    "x2=np.random.randn(100)\n",
    "\n",
    "axes[0,0].scatter(x1,x2)\n",
    "axes[0,0].set_title(\"Uncorrelated\")\n",
    "\n",
    "axes[0,1].scatter(x1,x1+x2)\n",
    "axes[0,1].set_title(\"weakly positively \\ncorrelated\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris \n",
    "# getting the iris data from sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DESCR': 'Iris Plants Database\\n====================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n',\n",
       " 'data': array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "        [ 4.9,  3. ,  1.4,  0.2],\n",
       "        [ 4.7,  3.2,  1.3,  0.2],\n",
       "        [ 4.6,  3.1,  1.5,  0.2],\n",
       "        [ 5. ,  3.6,  1.4,  0.2],\n",
       "        [ 5.4,  3.9,  1.7,  0.4],\n",
       "        [ 4.6,  3.4,  1.4,  0.3],\n",
       "        [ 5. ,  3.4,  1.5,  0.2],\n",
       "        [ 4.4,  2.9,  1.4,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 5.4,  3.7,  1.5,  0.2],\n",
       "        [ 4.8,  3.4,  1.6,  0.2],\n",
       "        [ 4.8,  3. ,  1.4,  0.1],\n",
       "        [ 4.3,  3. ,  1.1,  0.1],\n",
       "        [ 5.8,  4. ,  1.2,  0.2],\n",
       "        [ 5.7,  4.4,  1.5,  0.4],\n",
       "        [ 5.4,  3.9,  1.3,  0.4],\n",
       "        [ 5.1,  3.5,  1.4,  0.3],\n",
       "        [ 5.7,  3.8,  1.7,  0.3],\n",
       "        [ 5.1,  3.8,  1.5,  0.3],\n",
       "        [ 5.4,  3.4,  1.7,  0.2],\n",
       "        [ 5.1,  3.7,  1.5,  0.4],\n",
       "        [ 4.6,  3.6,  1. ,  0.2],\n",
       "        [ 5.1,  3.3,  1.7,  0.5],\n",
       "        [ 4.8,  3.4,  1.9,  0.2],\n",
       "        [ 5. ,  3. ,  1.6,  0.2],\n",
       "        [ 5. ,  3.4,  1.6,  0.4],\n",
       "        [ 5.2,  3.5,  1.5,  0.2],\n",
       "        [ 5.2,  3.4,  1.4,  0.2],\n",
       "        [ 4.7,  3.2,  1.6,  0.2],\n",
       "        [ 4.8,  3.1,  1.6,  0.2],\n",
       "        [ 5.4,  3.4,  1.5,  0.4],\n",
       "        [ 5.2,  4.1,  1.5,  0.1],\n",
       "        [ 5.5,  4.2,  1.4,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 5. ,  3.2,  1.2,  0.2],\n",
       "        [ 5.5,  3.5,  1.3,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 4.4,  3. ,  1.3,  0.2],\n",
       "        [ 5.1,  3.4,  1.5,  0.2],\n",
       "        [ 5. ,  3.5,  1.3,  0.3],\n",
       "        [ 4.5,  2.3,  1.3,  0.3],\n",
       "        [ 4.4,  3.2,  1.3,  0.2],\n",
       "        [ 5. ,  3.5,  1.6,  0.6],\n",
       "        [ 5.1,  3.8,  1.9,  0.4],\n",
       "        [ 4.8,  3. ,  1.4,  0.3],\n",
       "        [ 5.1,  3.8,  1.6,  0.2],\n",
       "        [ 4.6,  3.2,  1.4,  0.2],\n",
       "        [ 5.3,  3.7,  1.5,  0.2],\n",
       "        [ 5. ,  3.3,  1.4,  0.2],\n",
       "        [ 7. ,  3.2,  4.7,  1.4],\n",
       "        [ 6.4,  3.2,  4.5,  1.5],\n",
       "        [ 6.9,  3.1,  4.9,  1.5],\n",
       "        [ 5.5,  2.3,  4. ,  1.3],\n",
       "        [ 6.5,  2.8,  4.6,  1.5],\n",
       "        [ 5.7,  2.8,  4.5,  1.3],\n",
       "        [ 6.3,  3.3,  4.7,  1.6],\n",
       "        [ 4.9,  2.4,  3.3,  1. ],\n",
       "        [ 6.6,  2.9,  4.6,  1.3],\n",
       "        [ 5.2,  2.7,  3.9,  1.4],\n",
       "        [ 5. ,  2. ,  3.5,  1. ],\n",
       "        [ 5.9,  3. ,  4.2,  1.5],\n",
       "        [ 6. ,  2.2,  4. ,  1. ],\n",
       "        [ 6.1,  2.9,  4.7,  1.4],\n",
       "        [ 5.6,  2.9,  3.6,  1.3],\n",
       "        [ 6.7,  3.1,  4.4,  1.4],\n",
       "        [ 5.6,  3. ,  4.5,  1.5],\n",
       "        [ 5.8,  2.7,  4.1,  1. ],\n",
       "        [ 6.2,  2.2,  4.5,  1.5],\n",
       "        [ 5.6,  2.5,  3.9,  1.1],\n",
       "        [ 5.9,  3.2,  4.8,  1.8],\n",
       "        [ 6.1,  2.8,  4. ,  1.3],\n",
       "        [ 6.3,  2.5,  4.9,  1.5],\n",
       "        [ 6.1,  2.8,  4.7,  1.2],\n",
       "        [ 6.4,  2.9,  4.3,  1.3],\n",
       "        [ 6.6,  3. ,  4.4,  1.4],\n",
       "        [ 6.8,  2.8,  4.8,  1.4],\n",
       "        [ 6.7,  3. ,  5. ,  1.7],\n",
       "        [ 6. ,  2.9,  4.5,  1.5],\n",
       "        [ 5.7,  2.6,  3.5,  1. ],\n",
       "        [ 5.5,  2.4,  3.8,  1.1],\n",
       "        [ 5.5,  2.4,  3.7,  1. ],\n",
       "        [ 5.8,  2.7,  3.9,  1.2],\n",
       "        [ 6. ,  2.7,  5.1,  1.6],\n",
       "        [ 5.4,  3. ,  4.5,  1.5],\n",
       "        [ 6. ,  3.4,  4.5,  1.6],\n",
       "        [ 6.7,  3.1,  4.7,  1.5],\n",
       "        [ 6.3,  2.3,  4.4,  1.3],\n",
       "        [ 5.6,  3. ,  4.1,  1.3],\n",
       "        [ 5.5,  2.5,  4. ,  1.3],\n",
       "        [ 5.5,  2.6,  4.4,  1.2],\n",
       "        [ 6.1,  3. ,  4.6,  1.4],\n",
       "        [ 5.8,  2.6,  4. ,  1.2],\n",
       "        [ 5. ,  2.3,  3.3,  1. ],\n",
       "        [ 5.6,  2.7,  4.2,  1.3],\n",
       "        [ 5.7,  3. ,  4.2,  1.2],\n",
       "        [ 5.7,  2.9,  4.2,  1.3],\n",
       "        [ 6.2,  2.9,  4.3,  1.3],\n",
       "        [ 5.1,  2.5,  3. ,  1.1],\n",
       "        [ 5.7,  2.8,  4.1,  1.3],\n",
       "        [ 6.3,  3.3,  6. ,  2.5],\n",
       "        [ 5.8,  2.7,  5.1,  1.9],\n",
       "        [ 7.1,  3. ,  5.9,  2.1],\n",
       "        [ 6.3,  2.9,  5.6,  1.8],\n",
       "        [ 6.5,  3. ,  5.8,  2.2],\n",
       "        [ 7.6,  3. ,  6.6,  2.1],\n",
       "        [ 4.9,  2.5,  4.5,  1.7],\n",
       "        [ 7.3,  2.9,  6.3,  1.8],\n",
       "        [ 6.7,  2.5,  5.8,  1.8],\n",
       "        [ 7.2,  3.6,  6.1,  2.5],\n",
       "        [ 6.5,  3.2,  5.1,  2. ],\n",
       "        [ 6.4,  2.7,  5.3,  1.9],\n",
       "        [ 6.8,  3. ,  5.5,  2.1],\n",
       "        [ 5.7,  2.5,  5. ,  2. ],\n",
       "        [ 5.8,  2.8,  5.1,  2.4],\n",
       "        [ 6.4,  3.2,  5.3,  2.3],\n",
       "        [ 6.5,  3. ,  5.5,  1.8],\n",
       "        [ 7.7,  3.8,  6.7,  2.2],\n",
       "        [ 7.7,  2.6,  6.9,  2.3],\n",
       "        [ 6. ,  2.2,  5. ,  1.5],\n",
       "        [ 6.9,  3.2,  5.7,  2.3],\n",
       "        [ 5.6,  2.8,  4.9,  2. ],\n",
       "        [ 7.7,  2.8,  6.7,  2. ],\n",
       "        [ 6.3,  2.7,  4.9,  1.8],\n",
       "        [ 6.7,  3.3,  5.7,  2.1],\n",
       "        [ 7.2,  3.2,  6. ,  1.8],\n",
       "        [ 6.2,  2.8,  4.8,  1.8],\n",
       "        [ 6.1,  3. ,  4.9,  1.8],\n",
       "        [ 6.4,  2.8,  5.6,  2.1],\n",
       "        [ 7.2,  3. ,  5.8,  1.6],\n",
       "        [ 7.4,  2.8,  6.1,  1.9],\n",
       "        [ 7.9,  3.8,  6.4,  2. ],\n",
       "        [ 6.4,  2.8,  5.6,  2.2],\n",
       "        [ 6.3,  2.8,  5.1,  1.5],\n",
       "        [ 6.1,  2.6,  5.6,  1.4],\n",
       "        [ 7.7,  3. ,  6.1,  2.3],\n",
       "        [ 6.3,  3.4,  5.6,  2.4],\n",
       "        [ 6.4,  3.1,  5.5,  1.8],\n",
       "        [ 6. ,  3. ,  4.8,  1.8],\n",
       "        [ 6.9,  3.1,  5.4,  2.1],\n",
       "        [ 6.7,  3.1,  5.6,  2.4],\n",
       "        [ 6.9,  3.1,  5.1,  2.3],\n",
       "        [ 5.8,  2.7,  5.1,  1.9],\n",
       "        [ 6.8,  3.2,  5.9,  2.3],\n",
       "        [ 6.7,  3.3,  5.7,  2.5],\n",
       "        [ 6.7,  3. ,  5.2,  2.3],\n",
       "        [ 6.3,  2.5,  5. ,  1.9],\n",
       "        [ 6.5,  3. ,  5.2,  2. ],\n",
       "        [ 6.2,  3.4,  5.4,  2.3],\n",
       "        [ 5.9,  3. ,  5.1,  1.8]]),\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'],\n",
       "       dtype='<U10')}"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 5.4,  3.9,  1.7,  0.4],\n",
       "       [ 4.6,  3.4,  1.4,  0.3],\n",
       "       [ 5. ,  3.4,  1.5,  0.2],\n",
       "       [ 4.4,  2.9,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5.4,  3.7,  1.5,  0.2],\n",
       "       [ 4.8,  3.4,  1.6,  0.2],\n",
       "       [ 4.8,  3. ,  1.4,  0.1],\n",
       "       [ 4.3,  3. ,  1.1,  0.1],\n",
       "       [ 5.8,  4. ,  1.2,  0.2],\n",
       "       [ 5.7,  4.4,  1.5,  0.4],\n",
       "       [ 5.4,  3.9,  1.3,  0.4],\n",
       "       [ 5.1,  3.5,  1.4,  0.3],\n",
       "       [ 5.7,  3.8,  1.7,  0.3],\n",
       "       [ 5.1,  3.8,  1.5,  0.3],\n",
       "       [ 5.4,  3.4,  1.7,  0.2],\n",
       "       [ 5.1,  3.7,  1.5,  0.4],\n",
       "       [ 4.6,  3.6,  1. ,  0.2],\n",
       "       [ 5.1,  3.3,  1.7,  0.5],\n",
       "       [ 4.8,  3.4,  1.9,  0.2],\n",
       "       [ 5. ,  3. ,  1.6,  0.2],\n",
       "       [ 5. ,  3.4,  1.6,  0.4],\n",
       "       [ 5.2,  3.5,  1.5,  0.2],\n",
       "       [ 5.2,  3.4,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.6,  0.2],\n",
       "       [ 4.8,  3.1,  1.6,  0.2],\n",
       "       [ 5.4,  3.4,  1.5,  0.4],\n",
       "       [ 5.2,  4.1,  1.5,  0.1],\n",
       "       [ 5.5,  4.2,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5. ,  3.2,  1.2,  0.2],\n",
       "       [ 5.5,  3.5,  1.3,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 4.4,  3. ,  1.3,  0.2],\n",
       "       [ 5.1,  3.4,  1.5,  0.2],\n",
       "       [ 5. ,  3.5,  1.3,  0.3],\n",
       "       [ 4.5,  2.3,  1.3,  0.3],\n",
       "       [ 4.4,  3.2,  1.3,  0.2],\n",
       "       [ 5. ,  3.5,  1.6,  0.6],\n",
       "       [ 5.1,  3.8,  1.9,  0.4],\n",
       "       [ 4.8,  3. ,  1.4,  0.3],\n",
       "       [ 5.1,  3.8,  1.6,  0.2],\n",
       "       [ 4.6,  3.2,  1.4,  0.2],\n",
       "       [ 5.3,  3.7,  1.5,  0.2],\n",
       "       [ 5. ,  3.3,  1.4,  0.2],\n",
       "       [ 7. ,  3.2,  4.7,  1.4],\n",
       "       [ 6.4,  3.2,  4.5,  1.5],\n",
       "       [ 6.9,  3.1,  4.9,  1.5],\n",
       "       [ 5.5,  2.3,  4. ,  1.3],\n",
       "       [ 6.5,  2.8,  4.6,  1.5],\n",
       "       [ 5.7,  2.8,  4.5,  1.3],\n",
       "       [ 6.3,  3.3,  4.7,  1.6],\n",
       "       [ 4.9,  2.4,  3.3,  1. ],\n",
       "       [ 6.6,  2.9,  4.6,  1.3],\n",
       "       [ 5.2,  2.7,  3.9,  1.4],\n",
       "       [ 5. ,  2. ,  3.5,  1. ],\n",
       "       [ 5.9,  3. ,  4.2,  1.5],\n",
       "       [ 6. ,  2.2,  4. ,  1. ],\n",
       "       [ 6.1,  2.9,  4.7,  1.4],\n",
       "       [ 5.6,  2.9,  3.6,  1.3],\n",
       "       [ 6.7,  3.1,  4.4,  1.4],\n",
       "       [ 5.6,  3. ,  4.5,  1.5],\n",
       "       [ 5.8,  2.7,  4.1,  1. ],\n",
       "       [ 6.2,  2.2,  4.5,  1.5],\n",
       "       [ 5.6,  2.5,  3.9,  1.1],\n",
       "       [ 5.9,  3.2,  4.8,  1.8],\n",
       "       [ 6.1,  2.8,  4. ,  1.3],\n",
       "       [ 6.3,  2.5,  4.9,  1.5],\n",
       "       [ 6.1,  2.8,  4.7,  1.2],\n",
       "       [ 6.4,  2.9,  4.3,  1.3],\n",
       "       [ 6.6,  3. ,  4.4,  1.4],\n",
       "       [ 6.8,  2.8,  4.8,  1.4],\n",
       "       [ 6.7,  3. ,  5. ,  1.7],\n",
       "       [ 6. ,  2.9,  4.5,  1.5],\n",
       "       [ 5.7,  2.6,  3.5,  1. ],\n",
       "       [ 5.5,  2.4,  3.8,  1.1],\n",
       "       [ 5.5,  2.4,  3.7,  1. ],\n",
       "       [ 5.8,  2.7,  3.9,  1.2],\n",
       "       [ 6. ,  2.7,  5.1,  1.6],\n",
       "       [ 5.4,  3. ,  4.5,  1.5],\n",
       "       [ 6. ,  3.4,  4.5,  1.6],\n",
       "       [ 6.7,  3.1,  4.7,  1.5],\n",
       "       [ 6.3,  2.3,  4.4,  1.3],\n",
       "       [ 5.6,  3. ,  4.1,  1.3],\n",
       "       [ 5.5,  2.5,  4. ,  1.3],\n",
       "       [ 5.5,  2.6,  4.4,  1.2],\n",
       "       [ 6.1,  3. ,  4.6,  1.4],\n",
       "       [ 5.8,  2.6,  4. ,  1.2],\n",
       "       [ 5. ,  2.3,  3.3,  1. ],\n",
       "       [ 5.6,  2.7,  4.2,  1.3],\n",
       "       [ 5.7,  3. ,  4.2,  1.2],\n",
       "       [ 5.7,  2.9,  4.2,  1.3],\n",
       "       [ 6.2,  2.9,  4.3,  1.3],\n",
       "       [ 5.1,  2.5,  3. ,  1.1],\n",
       "       [ 5.7,  2.8,  4.1,  1.3],\n",
       "       [ 6.3,  3.3,  6. ,  2.5],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 7.1,  3. ,  5.9,  2.1],\n",
       "       [ 6.3,  2.9,  5.6,  1.8],\n",
       "       [ 6.5,  3. ,  5.8,  2.2],\n",
       "       [ 7.6,  3. ,  6.6,  2.1],\n",
       "       [ 4.9,  2.5,  4.5,  1.7],\n",
       "       [ 7.3,  2.9,  6.3,  1.8],\n",
       "       [ 6.7,  2.5,  5.8,  1.8],\n",
       "       [ 7.2,  3.6,  6.1,  2.5],\n",
       "       [ 6.5,  3.2,  5.1,  2. ],\n",
       "       [ 6.4,  2.7,  5.3,  1.9],\n",
       "       [ 6.8,  3. ,  5.5,  2.1],\n",
       "       [ 5.7,  2.5,  5. ,  2. ],\n",
       "       [ 5.8,  2.8,  5.1,  2.4],\n",
       "       [ 6.4,  3.2,  5.3,  2.3],\n",
       "       [ 6.5,  3. ,  5.5,  1.8],\n",
       "       [ 7.7,  3.8,  6.7,  2.2],\n",
       "       [ 7.7,  2.6,  6.9,  2.3],\n",
       "       [ 6. ,  2.2,  5. ,  1.5],\n",
       "       [ 6.9,  3.2,  5.7,  2.3],\n",
       "       [ 5.6,  2.8,  4.9,  2. ],\n",
       "       [ 7.7,  2.8,  6.7,  2. ],\n",
       "       [ 6.3,  2.7,  4.9,  1.8],\n",
       "       [ 6.7,  3.3,  5.7,  2.1],\n",
       "       [ 7.2,  3.2,  6. ,  1.8],\n",
       "       [ 6.2,  2.8,  4.8,  1.8],\n",
       "       [ 6.1,  3. ,  4.9,  1.8],\n",
       "       [ 6.4,  2.8,  5.6,  2.1],\n",
       "       [ 7.2,  3. ,  5.8,  1.6],\n",
       "       [ 7.4,  2.8,  6.1,  1.9],\n",
       "       [ 7.9,  3.8,  6.4,  2. ],\n",
       "       [ 6.4,  2.8,  5.6,  2.2],\n",
       "       [ 6.3,  2.8,  5.1,  1.5],\n",
       "       [ 6.1,  2.6,  5.6,  1.4],\n",
       "       [ 7.7,  3. ,  6.1,  2.3],\n",
       "       [ 6.3,  3.4,  5.6,  2.4],\n",
       "       [ 6.4,  3.1,  5.5,  1.8],\n",
       "       [ 6. ,  3. ,  4.8,  1.8],\n",
       "       [ 6.9,  3.1,  5.4,  2.1],\n",
       "       [ 6.7,  3.1,  5.6,  2.4],\n",
       "       [ 6.9,  3.1,  5.1,  2.3],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 6.8,  3.2,  5.9,  2.3],\n",
       "       [ 6.7,  3.3,  5.7,  2.5],\n",
       "       [ 6.7,  3. ,  5.2,  2.3],\n",
       "       [ 6.3,  2.5,  5. ,  1.9],\n",
       "       [ 6.5,  3. ,  5.2,  2. ],\n",
       "       [ 6.2,  3.4,  5.4,  2.3],\n",
       "       [ 5.9,  3. ,  5.1,  1.8]])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store the data matrix into something\n",
    "X=iris.data\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 1 import the ML algorithm into python\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 2 instantiate the estimator - creating an instance of an classifier\n",
    "\n",
    "knn=KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.neighbors.classification.KNeighborsClassifier"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "print(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 4 make predictions for new observation\n",
    "\n",
    "knn.predict([[1,2,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want to predict more than 1 case \n",
    "\n",
    "X_new=[[1,2,3,4],[1,3,2,4]]\n",
    "knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want to set k=5, and put everyting together\n",
    "\n",
    "knn2=KNeighborsClassifier(n_neighbors=5)\n",
    "knn2.fit(X,y)\n",
    "knn2.predict(X_new)\n",
    "\n",
    "# how do we know WHICH PARAMETER IS BETTER? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 5 test for accuracy\n",
    "\n",
    "knn2=KNeighborsClassifier(n_neighbors=5)\n",
    "knn2.fit(X,y)\n",
    "knn2.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the predicted results\n",
    "y_pred=knn2.predict(X)\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute classification accuracy\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96666666666666667"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# putting everything together \n",
    "\n",
    "knn=KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X,y)\n",
    "knn.predict(X)\n",
    "y_pred=knn.predict(X)\n",
    "metrics.accuracy_score(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94666666666666666"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's test which parameter for K is better? 1 or 5? \n",
    "\n",
    "knn_1=KNeighborsClassifier(n_neighbors=1)\n",
    "knn_1.fit(X_train,y_train)\n",
    "y_pred=knn_1.predict(X_test)\n",
    "metrics.accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95999999999999996"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_2=KNeighborsClassifier(n_neighbors=5)\n",
    "knn_2.fit(X_train,y_train)\n",
    "knn_2.predict(X_test)\n",
    "y_pred=knn_2.predict(X_test) \n",
    "metrics.accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# doing this the hardway \n",
    "# WHAT IF WE DONT HAVE SKLEARN \n",
    "\n",
    "def splitdata(data,percent,train=[],test=[]):\n",
    "    trainingquota=int(len(data)*percent)\n",
    "    index=0\n",
    "    loclist=[]\n",
    "    while index<trainingquota:\n",
    "        loc=int(np.random.uniform()*len(data))\n",
    "        if (loc not in loclist) or (len(loclist)==0):\n",
    "            train.append(data[loc])\n",
    "            loclist.append(loc)\n",
    "            index=index+1\n",
    "        else:\n",
    "            continue\n",
    "    for i in range(len(data)): \n",
    "        if i not in loclist:\n",
    "            test.append(data[i])\n",
    "\n",
    "trainingset=[]\n",
    "testset=[]\n",
    "data=iris.data\n",
    "splitdata(data,0.4,trainingset,testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "print(len(trainingset))\n",
    "print(len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define similarity based on Euclidean distance\n",
    "\n",
    "def euclidean(item1, item2, nvar):\n",
    "    distance=0\n",
    "    for x in range(nvar):\n",
    "        distance=distance+(item1[x]-item2[x])**2\n",
    "    return np.sqrt(distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.74165738677\n"
     ]
    }
   ],
   "source": [
    "data1=[1,2,3,'a']\n",
    "data2=[4,4,4,'b']\n",
    "distance=euclidean(data1,data2,3)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get neighbor \n",
    "\n",
    "def getNeighbor(trainset, testinstance,k):\n",
    "    distancelist=[]\n",
    "    length=len(testinstance)-1\n",
    "    for x in range(len(trainset)):\n",
    "        dist=euclidean(testinstance,trainset[x],length)\n",
    "        distancelist.append((trainset[x],dist))\n",
    "    distancelist=np.array(distancelist)\n",
    "    distancelist=distancelist[distancelist[:,1].argsort()]#sorting according to distance\n",
    "    neighborlist=[]\n",
    "    for x in range(k):\n",
    "        neighborlist.append(distancelist[x][0])\n",
    "    return neighborlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 5, 2, 'b'], [4, 4, 4, 'b']]\n"
     ]
    }
   ],
   "source": [
    "trainset=[[2,2,2,'a'],[4,4,4,'b'],[5,5,2,'b']]\n",
    "testitem=[5,5,5]\n",
    "neighbors=getNeighbor(trainset,testitem,2)\n",
    "print(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.84484914  0.51772013  0.7622843 ]\n",
      " [ 0.57075822  0.90377167  0.07123738]\n",
      " [ 0.19095498  0.09225594  0.64690327]\n",
      " [ 0.01740558  0.19879599  0.2332729 ]\n",
      " [ 0.03294523  0.51604261  0.06733002]\n",
      " [ 0.69213022  0.63259806  0.75323869]\n",
      " [ 0.93525375  0.00557039  0.2527441 ]\n",
      " [ 0.46186774  0.07537923  0.5514047 ]\n",
      " [ 0.69653458  0.75371722  0.93523111]\n",
      " [ 0.92366565  0.55941279  0.65175471]]\n",
      "\n",
      "\n",
      "\n",
      "[[ 0.93525375  0.00557039  0.2527441 ]\n",
      " [ 0.46186774  0.07537923  0.5514047 ]\n",
      " [ 0.19095498  0.09225594  0.64690327]\n",
      " [ 0.01740558  0.19879599  0.2332729 ]\n",
      " [ 0.03294523  0.51604261  0.06733002]\n",
      " [ 0.84484914  0.51772013  0.7622843 ]\n",
      " [ 0.92366565  0.55941279  0.65175471]\n",
      " [ 0.69213022  0.63259806  0.75323869]\n",
      " [ 0.69653458  0.75371722  0.93523111]\n",
      " [ 0.57075822  0.90377167  0.07123738]]\n"
     ]
    }
   ],
   "source": [
    "a=np.random.rand(10,3)\n",
    "print(a)\n",
    "print('\\n\\n')\n",
    "print(a[a[:,1].argsort()])# sort the second column of a and give me the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function 4: input neighbors, output predicted y\n",
    "#make predictions based on neighbors we caculated \n",
    "def getprediction(neighbors): \n",
    "    votes={} \n",
    "    for x in range(len(neighbors)): \n",
    "        prediction=neighbors[x][-1]\n",
    "        if prediction in votes:\n",
    "            votes[prediction]+=1\n",
    "        else:\n",
    "            votes[prediction]=1\n",
    "    sortedvotes=sorted([(v,k)for k,v in votes.items()],reverse=True)\n",
    "    return sortedvotes[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "neighbors=[[1,1,1,'a'],[2,2,2,'a'],[3,3,3,'b']]\n",
    "prediction=getprediction(neighbors)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for accuracy\n",
    "def getaccuracy(testset,predictions):\n",
    "    correct=0\n",
    "    for x in range(len(testset)): \n",
    "        if testset[x][-1]==predictions[x]:\n",
    "            correct+=1\n",
    "        return(round((correct/len(testset))*100,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.333\n"
     ]
    }
   ],
   "source": [
    "testset=[[1,1,1,'a'],[2,2,2,'a'],[3,3,3,'b']]\n",
    "predictions=['a','a','a']\n",
    "accuracy=getaccuracy(testset,predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    trainingset=[]\n",
    "    testset=[]\n",
    "    split=0.5\n",
    "    data=pd.concat([pd.DataFrame(iris.data),pd.DataFrame(iris.target)],axis=1)\n",
    "    data=data.values.tolist()\n",
    "    splitdata(data,split,trainingset,testset)\n",
    "    #generate predictions\n",
    "    predictions=[]\n",
    "    k=3\n",
    "    for x in range(len(testset)):\n",
    "        neighbors=getNeighbor(trainingset,testset[x],k)\n",
    "        result=getprediction(neighbors)\n",
    "        predictions.append(result)\n",
    "    accuracy=getaccuracy(testset,predictions)\n",
    "    print('accuracy:', accuracy,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.333 %\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
